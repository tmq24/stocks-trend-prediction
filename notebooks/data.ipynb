{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5b8b2c00",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import ta \n",
        "\n",
        "# Tiingo API\n",
        "API_TOKEN = '4f730c224705f43752f4c8bdf20cfe9fb56ce8c5'\n",
        "BASE_URL = 'https://api.tiingo.com/tiingo/daily'\n",
        "\n",
        "STOCKS = [\n",
        "    'AAPL',   # Apple - Tech\n",
        "    'HSBC',   # HSBC - Finance\n",
        "    'PEP',    # Pepsi - Consumer\n",
        "    'TM',     # Toyota - Automotive\n",
        "    'TCEHY',  # Tencent - Tech\n",
        "]\n",
        "\n",
        "START_DATE = '2015-06-20'\n",
        "END_DATE = '2025-06-20'\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "if os.path.basename(current_dir) == 'notebooks':\n",
        "    OUTPUT_DIR = os.path.join(os.path.dirname(current_dir), 'data')\n",
        "else:\n",
        "    OUTPUT_DIR = os.path.join(current_dir, 'data')\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6faeff35",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_stock_data(ticker, start_date, end_date, api_token, base_url):\n",
        "    \"\"\"Fetch historical stock prices from Tiingo API (OHLCV only)\"\"\"\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "    url = f'{base_url}/{ticker}/prices?startDate={start_date}&endDate={end_date}&token={api_token}'\n",
        "    \n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        \n",
        "        if data:\n",
        "            df = pd.DataFrame(data)\n",
        "            df['ticker'] = ticker\n",
        "            df['date'] = pd.to_datetime(df['date']).dt.tz_localize(None)\n",
        "            df.columns = [c.lower() for c in df.columns]\n",
        "            df = df[['date', 'open', 'high', 'low', 'close', 'volume', 'ticker']].copy()\n",
        "            df = df.sort_values('date').reset_index(drop=True)\n",
        "            df = df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
        "            return df\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"  Error fetching {ticker}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Data Cleaning\n",
        "def clean_data(df):\n",
        "    \"\"\"\n",
        "    Clean and normalize stock data.\n",
        "    - Forward-fill volume only if needed (very limited)\n",
        "    - Remove duplicates\n",
        "    - Ensure date continuity\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    if df['volume'].isna().any():\n",
        "        df['volume'] = df['volume'].fillna(method='ffill', limit=1)\n",
        "    df = df.dropna(subset=['open', 'high', 'low', 'close', 'volume'])\n",
        "    return df\n",
        "\n",
        "\n",
        "# Calculate Technical Indicators\n",
        "def add_technical_indicators(df):\n",
        "    \"\"\"\n",
        "    Add technical indicators to a single stock's dataframe.\n",
        "    All features at time t use data <= t-1.\n",
        "    Strategy: Calculate indicators, then shift by 1 period.\n",
        "    Features generated:\n",
        "    - Returns: return_1d, return_5d, log_return\n",
        "    - Trend/Momentum: SMA_10, SMA_20, EMA_10, momentum_5, momentum_10, price_dev_SMA_20\n",
        "    - Volatility: rolling_std_5, rolling_std_20, ATR_14\n",
        "    - Volume: Volume_MA_5, Volume_ratio, OBV\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Returns\n",
        "    df['return_1d'] = df['close'].pct_change()\n",
        "    df['return_5d'] = df['close'].pct_change(5)\n",
        "    df['log_return'] = np.log(df['close'] / df['close'].shift(1))\n",
        "    \n",
        "    # Moving Averages\n",
        "    df['SMA_10'] = ta.trend.sma_indicator(df['close'], window=10)\n",
        "    df['SMA_20'] = ta.trend.sma_indicator(df['close'], window=20)\n",
        "    df['EMA_10'] = ta.trend.ema_indicator(df['close'], window=10)\n",
        "    \n",
        "    # Price deviation from SMA_20\n",
        "    df['price_dev_SMA_20'] = (df['close'] - df['SMA_20']) / (df['SMA_20'] + 1e-8)\n",
        "    \n",
        "    # Momentum\n",
        "    df['momentum_5'] = df['close'] - df['close'].shift(5)\n",
        "    df['momentum_10'] = df['close'] - df['close'].shift(10)\n",
        "    \n",
        "    # RSI\n",
        "    df['RSI_14'] = ta.momentum.rsi(df['close'], window=14)\n",
        "    \n",
        "    # MACD\n",
        "    macd = ta.trend.MACD(df['close'])\n",
        "    df['MACD'] = macd.macd()\n",
        "    df['MACD_signal'] = macd.macd_signal()\n",
        "    df['MACD_diff'] = macd.macd_diff()\n",
        "    \n",
        "    # Bollinger Bands\n",
        "    bb = ta.volatility.BollingerBands(df['close'], window=20)\n",
        "    df['BB_upper'] = bb.bollinger_hband()\n",
        "    df['BB_lower'] = bb.bollinger_lband()\n",
        "    df['BB_middle'] = bb.bollinger_mavg()\n",
        "    df['BB_width'] = (df['BB_upper'] - df['BB_lower']) / (df['BB_middle'] + 1e-8)\n",
        "    \n",
        "    # Volatility\n",
        "    df['rolling_std_5'] = df['close'].pct_change().rolling(5).std()\n",
        "    df['rolling_std_20'] = df['close'].pct_change().rolling(20).std()\n",
        "    df['ATR_14'] = ta.volatility.average_true_range(df['high'], df['low'], df['close'], window=14)\n",
        "    \n",
        "    # Volume indicators\n",
        "    df['Volume_MA_5'] = df['volume'].rolling(5).mean()\n",
        "    df['Volume_ratio'] = df['volume'] / (df['Volume_MA_5'] + 1e-8)\n",
        "    df['OBV'] = ta.volume.on_balance_volume(df['close'], df['volume'])\n",
        "    \n",
        "    tech_cols = [\n",
        "        # Returns\n",
        "        'return_1d', 'return_5d', 'log_return',\n",
        "        # Trend/Momentum\n",
        "        'SMA_10', 'SMA_20', 'EMA_10', 'price_dev_SMA_20', 'momentum_5', 'momentum_10',\n",
        "        # RSI, MACD\n",
        "        'RSI_14', 'MACD', 'MACD_signal', 'MACD_diff',\n",
        "        # Bollinger Bands\n",
        "        'BB_upper', 'BB_lower', 'BB_middle', 'BB_width',\n",
        "        # Volatility\n",
        "        'rolling_std_5', 'rolling_std_20', 'ATR_14',\n",
        "        # Volume\n",
        "        'Volume_MA_5', 'Volume_ratio', 'OBV'\n",
        "    ]\n",
        "    \n",
        "    for col in tech_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].shift(1)\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "def process_single_stock(ticker, start_date, end_date, api_token, base_url):\n",
        "    \"\"\"\n",
        "    Complete pipeline for a single stock (OHLCV-only):\n",
        "    1. Fetch stock prices from Tiingo API\n",
        "    2. Clean data\n",
        "    3. Calculate technical indicators\n",
        "    \"\"\"\n",
        "    stock_df = fetch_stock_data(ticker, start_date, end_date, api_token, base_url)\n",
        "    if stock_df is None:\n",
        "        print(f\"  Failed to fetch stock data for {ticker}\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"  Stock data: {len(stock_df)} records\")\n",
        "    \n",
        "    stock_df = clean_data(stock_df)\n",
        "    print(f\"  After cleaning: {len(stock_df)} records\")\n",
        "    \n",
        "    stock_df = add_technical_indicators(stock_df)\n",
        "    \n",
        "    initial_len = len(stock_df)\n",
        "    stock_df = stock_df.dropna().reset_index(drop=True)\n",
        "    print(f\"  Final: {len(stock_df)} records (dropped {initial_len - len(stock_df)} rows with NaN)\")\n",
        "    \n",
        "    return stock_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cdeff2ae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Stocks: ['AAPL', 'HSBC', 'PEP', 'TM', 'TCEHY']\n",
            "Period: 2015-06-20 to 2025-06-20\n",
            "Output: c:\\Users\\minhq\\Documents\\Projects\\stocks-trend-prediction\\data/{TICKER}.csv\n",
            "======================================================================\n",
            "\n",
            "[1/5]  Stock data: 2515 records\n",
            "  After cleaning: 2515 records\n",
            "  Final: 2481 records (dropped 34 rows with NaN)\n",
            "  Saved: c:\\Users\\minhq\\Documents\\Projects\\stocks-trend-prediction\\data/AAPL.csv\n",
            "\n",
            "[2/5]  Stock data: 2515 records\n",
            "  After cleaning: 2515 records\n",
            "  Final: 2481 records (dropped 34 rows with NaN)\n",
            "  Saved: c:\\Users\\minhq\\Documents\\Projects\\stocks-trend-prediction\\data/HSBC.csv\n",
            "\n",
            "[3/5]  Stock data: 2515 records\n",
            "  After cleaning: 2515 records\n",
            "  Final: 2481 records (dropped 34 rows with NaN)\n",
            "  Saved: c:\\Users\\minhq\\Documents\\Projects\\stocks-trend-prediction\\data/PEP.csv\n",
            "\n",
            "[4/5]  Stock data: 2515 records\n",
            "  After cleaning: 2515 records\n",
            "  Final: 2481 records (dropped 34 rows with NaN)\n",
            "  Saved: c:\\Users\\minhq\\Documents\\Projects\\stocks-trend-prediction\\data/TM.csv\n",
            "\n",
            "[5/5]  Stock data: 2515 records\n",
            "  After cleaning: 2515 records\n",
            "  Final: 2481 records (dropped 34 rows with NaN)\n",
            "  Saved: c:\\Users\\minhq\\Documents\\Projects\\stocks-trend-prediction\\data/TCEHY.csv\n"
          ]
        }
      ],
      "source": [
        "def process_all_stocks(stocks, start_date, end_date, api_token, base_url, output_dir):\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Stocks: {stocks}\")\n",
        "    print(f\"Period: {start_date} to {end_date}\")\n",
        "    print(f\"Output: {output_dir}/{{TICKER}}.csv\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for i, ticker in enumerate(stocks, 1):\n",
        "        print(f\"\\n[{i}/{len(stocks)}]\", end=\"\")\n",
        "        \n",
        "        df = process_single_stock(\n",
        "            ticker, start_date, end_date, \n",
        "            api_token, base_url\n",
        "        )\n",
        "        \n",
        "        if df is not None:\n",
        "            output_file = f'{output_dir}/{ticker}.csv'\n",
        "            df.to_csv(output_file, index=False)\n",
        "            \n",
        "            results[ticker] = {\n",
        "                'records': len(df),\n",
        "                'columns': len(df.columns),\n",
        "                'date_range': f\"{df['date'].min()} to {df['date'].max()}\",\n",
        "            }\n",
        "            print(f\"  Saved: {output_file}\")\n",
        "        else:\n",
        "            results[ticker] = None\n",
        "        time.sleep(1.0)\n",
        "    return results\n",
        "\n",
        "results = process_all_stocks(\n",
        "    STOCKS, START_DATE, END_DATE, \n",
        "    API_TOKEN, BASE_URL, OUTPUT_DIR\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45dec05f",
      "metadata": {},
      "source": [
        "### Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a0ae039e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "AAPL:\n",
            "  Records: 2481 | Columns: 30\n",
            "  Date Range: 2015-08-10 00:00:00 to 2025-06-20 00:00:00\n",
            "\n",
            "HSBC:\n",
            "  Records: 2481 | Columns: 30\n",
            "  Date Range: 2015-08-10 00:00:00 to 2025-06-20 00:00:00\n",
            "\n",
            "PEP:\n",
            "  Records: 2481 | Columns: 30\n",
            "  Date Range: 2015-08-10 00:00:00 to 2025-06-20 00:00:00\n",
            "\n",
            "TM:\n",
            "  Records: 2481 | Columns: 30\n",
            "  Date Range: 2015-08-10 00:00:00 to 2025-06-20 00:00:00\n",
            "\n",
            "TCEHY:\n",
            "  Records: 2481 | Columns: 30\n",
            "  Date Range: 2015-08-10 00:00:00 to 2025-06-20 00:00:00\n"
          ]
        }
      ],
      "source": [
        "for ticker, info in results.items():\n",
        "    if info:\n",
        "        print(f\"\\n{ticker}:\")\n",
        "        print(f\"  Records: {info['records']} | Columns: {info['columns']}\")\n",
        "        print(f\"  Date Range: {info['date_range']}\")\n",
        "    else:\n",
        "        print(f\"\\n{ticker}: FAILED\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv (3.13.5)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
